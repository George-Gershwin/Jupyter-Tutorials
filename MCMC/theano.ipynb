{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import theano.tensor as T\n",
    "from theano import function, shared\n",
    "from scipy.optimize import approx_fprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(vals, func, releps=1e-3, abseps=None, mineps=1e-9, reltol=1e-3,\n",
    "                epsscale=0.5):\n",
    "    \"\"\"\n",
    "    Calculate the partial derivatives of a function at a set of values. The\n",
    "    derivatives are calculated using the central difference, using an iterative\n",
    "    method to check that the values converge as step size decreases.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vals: array_like\n",
    "        A set of values, that are passed to a function, at which to calculate\n",
    "        the gradient of that function\n",
    "    func:\n",
    "        A function that takes in an array of values.\n",
    "    releps: float, array_like, 1e-3\n",
    "        The initial relative step size for calculating the derivative.\n",
    "    abseps: float, array_like, None\n",
    "        The initial absolute step size for calculating the derivative.\n",
    "        This overrides `releps` if set.\n",
    "        `releps` is set then that is used.\n",
    "    mineps: float, 1e-9\n",
    "        The minimum relative step size at which to stop iterations if no\n",
    "        convergence is achieved.\n",
    "    epsscale: float, 0.5\n",
    "        The factor by which releps if scaled in each iteration.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    grads: array_like\n",
    "        An array of gradients for each non-fixed value.\n",
    "    \"\"\"\n",
    "\n",
    "    grads = np.zeros(len(vals))\n",
    "\n",
    "    # maximum number of times the gradient can change sign\n",
    "    flipflopmax = 10.\n",
    "\n",
    "    # set steps\n",
    "    if abseps is None:\n",
    "        if isinstance(releps, float):\n",
    "            eps = np.abs(vals)*releps\n",
    "            eps[eps == 0.] = releps  # if any values are zero set eps to releps\n",
    "            teps = releps*np.ones(len(vals))\n",
    "        elif isinstance(releps, (list, np.ndarray)):\n",
    "            if len(releps) != len(vals):\n",
    "                raise ValueError(\"Problem with input relative step sizes\")\n",
    "            eps = np.multiply(np.abs(vals), releps)\n",
    "            eps[eps == 0.] = np.array(releps)[eps == 0.]\n",
    "            teps = releps\n",
    "        else:\n",
    "            raise RuntimeError(\"Relative step sizes are not a recognised type!\")\n",
    "    else:\n",
    "        if isinstance(abseps, float):\n",
    "            eps = abseps*np.ones(len(vals))\n",
    "        elif isinstance(abseps, (list, np.ndarray)):\n",
    "            if len(abseps) != len(vals):\n",
    "                raise ValueError(\"Problem with input absolute step sizes\")\n",
    "            eps = np.array(abseps)\n",
    "        else:\n",
    "            raise RuntimeError(\"Absolute step sizes are not a recognised type!\")\n",
    "        teps = eps\n",
    "\n",
    "    # for each value in vals calculate the gradient\n",
    "    count = 0\n",
    "    for i in range(len(vals)):\n",
    "        # initial parameter diffs\n",
    "        leps = eps[i]\n",
    "        cureps = teps[i]\n",
    "\n",
    "        flipflop = 0\n",
    "\n",
    "        # get central finite difference\n",
    "        fvals = np.copy(vals)\n",
    "        bvals = np.copy(vals)\n",
    "\n",
    "        # central difference\n",
    "        fvals[i] += 0.5*leps  # change forwards distance to half eps\n",
    "        bvals[i] -= 0.5*leps  # change backwards distance to half eps\n",
    "        cdiff = (func(fvals)-func(bvals))/leps\n",
    "\n",
    "        while 1:\n",
    "            fvals[i] -= 0.5*leps  # remove old step\n",
    "            bvals[i] += 0.5*leps\n",
    "\n",
    "            # change the difference by a factor of two\n",
    "            cureps *= epsscale\n",
    "            if cureps < mineps or flipflop > flipflopmax:\n",
    "                # if no convergence set flat derivative (TODO: check if there is a better thing to do instead)\n",
    "                warnings.warn(\"Derivative calculation did not converge: setting flat derivative.\")\n",
    "                grads[count] = 0.\n",
    "                break\n",
    "            leps *= epsscale\n",
    "\n",
    "            # central difference\n",
    "            fvals[i] += 0.5*leps  # change forwards distance to half eps\n",
    "            bvals[i] -= 0.5*leps  # change backwards distance to half eps\n",
    "            cdiffnew = (func(fvals)-func(bvals))/leps\n",
    "\n",
    "            if cdiffnew == cdiff:\n",
    "                grads[count] = cdiff\n",
    "                break\n",
    "\n",
    "            # check whether previous diff and current diff are the same within reltol\n",
    "            rat = (cdiff/cdiffnew)\n",
    "            if np.isfinite(rat) and rat > 0.:\n",
    "                # gradient has not changed sign\n",
    "                if np.abs(1.-rat) < reltol:\n",
    "                    grads[count] = cdiffnew\n",
    "                    break\n",
    "                else:\n",
    "                    cdiff = cdiffnew\n",
    "                    continue\n",
    "            else:\n",
    "                cdiff = cdiffnew\n",
    "                flipflop += 1\n",
    "                continue\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(xk):\n",
    "    return xk[0] ** 2 + xk[1] ** 2\n",
    "\n",
    "def grad_f(xk):\n",
    "    return np.array([2*xk[0], 2*xk[1]])\n",
    "\n",
    "f([1, 2])\n",
    "grad_f([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx_fprime([1, 2], f, 0.001)\n",
    "\n",
    "gradients(np.array([1, 2]), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = T.dscalar('x')\n",
    "y = T.dscalar('y')\n",
    "z = x + y\n",
    "\n",
    "\n",
    "f = function([x, y], z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'theano' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0bff31fca25b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfvector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# declare variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m              \u001b[1;31m# build symbolic expression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# compile function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m77\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m22\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'theano' is not defined"
     ]
    }
   ],
   "source": [
    "a = T.fvector() # declare variable\n",
    "out = a[0:2]              # build symbolic expression\n",
    "f = theano.function([a], out)   # compile function\n",
    "f(np.asarray([0, 1, 2.2, 45, 77, 22], dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = shared(0)\n",
    "inc = T.iscalar('inc')\n",
    "accumulator = function([inc], state, updates=[(state, state+inc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(39)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accumulator(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(54)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
